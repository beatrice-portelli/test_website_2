@inproceedings{portelli-etal-2022-ailab,
    title = "{AILAB}-{U}dine@{SMM}4{H}`22: Limits of Transformers and {BERT} Ensembles",
    author = "Portelli, Beatrice  and
      Scaboro, Simone  and
      Chersoni, Emmanuele  and
      Santus, Enrico  and
      Serra, Giuseppe",
    editor = "Gonzalez-Hernandez, Graciela  and
      Weissenbacher, Davy",
    booktitle = "Proceedings of The Seventh Workshop on Social Media Mining for Health Applications, Workshop {\&} Shared Task",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.smm4h-1.36/",
    pages = "130--134",
    abstract = "This paper describes the models developed by the AILAB-Udine team for the SMM4H`22 Shared Task. We explored the limits of Transformer based models on text classification, entity extraction and entity normalization, tackling Tasks 1, 2, 5, 6 and 10. The main takeaways we got from participating in different tasks are: the overwhelming positive effects of combining different architectures when using ensemble learning, and the great potential of generative models for term normalization."
}